{"searchDocs":[{"title":"ğŸ“˜ Tools, libraries, and concepts","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/adding-memory/concepts","content":"","keywords":"","version":"Next"},{"title":"RunnableWithMessageHistoryâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/adding-memory/concepts#runnablewithmessagehistory","content":" Runnable that manages (reads, updates) chat message history for another Runnable. By default, it organizes chat history based on a session ID. ","version":"Next","tagName":"h2"},{"title":"ğŸ‘ Add memory to agents using MongoDB","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/adding-memory/adding-memory","content":"ğŸ‘ Add memory to agents using MongoDB The final step in this lab is to add conversational message history as a form of memory for the agent. Message history in this case will be stored in and retrieved from a MongoDB collection. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 9: Add memory to agents using MongoDB section in the notebook to add memory to the basic tool calling agent we created previously. The answers for code blocks in this section are as follows: CODE_BLOCK_22 Answer return MongoDBChatMessageHistory( MONGODB_URI, session_id, database_name=DB_NAME, collection_name=&quot;history&quot; ) CODE_BLOCK_23 Answer MessagesPlaceholder(&quot;chat_history&quot;) CODE_BLOCK_24 Answer RunnableWithMessageHistory( agent_executor, get_message_history, input_messages_key=&quot;input&quot;, history_messages_key=&quot;chat_history&quot;, ) CODE_BLOCK_25 Answer agent_with_chat_history.invoke( {&quot;input&quot;: &quot;What is the title of the first paper you found?&quot;}, config={&quot;configurable&quot;: {&quot;session_id&quot;: &quot;my-session&quot;}}, ) ","keywords":"","version":"Next"},{"title":"ğŸ“˜ Tools, libraries, and concepts","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/agent-tools/concepts","content":"","keywords":"","version":"Next"},{"title":"datasetsâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/agent-tools/concepts#datasets","content":" Library used to download a dataset of Arxiv papers from Hugging Face.  ","version":"Next","tagName":"h2"},{"title":"ArxivLoaderâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/agent-tools/concepts#arxivloader","content":" Document loader class in LangChain that used to load research papers from Arxiv.org as LangChain Document objects.  ","version":"Next","tagName":"h2"},{"title":"PyMongoâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/agent-tools/concepts#pymongo","content":" Python driver for MongoDB. Used to connect to MongoDB databases, delete and insert documents into a MongoDB collection.  ","version":"Next","tagName":"h2"},{"title":"LangChain integrationsâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/agent-tools/concepts#langchain-integrations","content":" Standalone langchain-{provider} packages for improved versioning, dependency management and testing. You will come across the following in this lab:  langchain-mongodb: Used to create a MongoDB Atlas vector store and also to store and retrieve chat message history from MongoDB langchain-huggingface: To access open-source embedding models from HuggingFace langchain-fireworks: To use Firework AI's chat completion models  ","version":"Next","tagName":"h2"},{"title":"LangChain Expression Language (LCEL)â€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/agent-tools/concepts#langchain-expression-language-lcel","content":" LCEL provides a declarative way to chain together prompts, data processing steps, calls to LLMs, and tools. Each unit in a chain is called a Runnable and can be invoked, streamed and transformed on its own.  ","version":"Next","tagName":"h2"},{"title":"RunnableLambdaâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/agent-tools/concepts#runnablelambda","content":" RunnableLambda converts any arbitrary Python function into a LangChain Runnable. ","version":"Next","tagName":"h2"},{"title":"ğŸ‘ Instantiate chat completion LLM","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/agent-tools/chat-completion-llm","content":"ğŸ‘ Instantiate chat completion LLM Let's instantiate the chat completion LLM to use as the &quot;brain&quot; of our agent and for any of the tools if required. We will use Fireworks AI's free AND open-source firefunction-v1 model via the ChatFireworks API in LangChain. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 5: Instantiate chat completion LLM section in the notebook to create an instance of ChatFireworks with the firefunction-v1 model. The answers for code blocks in this section are as follows: CODE_BLOCK_8 Answer ChatFireworks( model=&quot;accounts/fireworks/models/firefunction-v1&quot;, temperature=0.0, max_tokens=1024 ) ","keywords":"","version":"Next"},{"title":"ğŸ‘ Create the agent's knowledge base","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/agent-tools/knowledge-base","content":"ğŸ‘ Create the agent's knowledge base One of the tools that the AI research agent has access to is a question-answering tool that retrieves information from a knowledge base (MongoDB collection) and uses it to answer questions. But first, we need to create the knowledge base. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 3: Create a knowledge base section in the notebook to download a dataset of Arxiv papers from Hugging Face and ingest it into a MongoDB collection which will serve as our agent's knowledge base. The answers for code blocks in this section are as follows: CODE_BLOCK_4 Answer MongoClient(MONGODB_URI) CODE_BLOCK_5 Answer client[DB_NAME][COLLECTION_NAME] CODE_BLOCK_6 Answer collection.delete_many({}) CODE_BLOCK_7 Answer collection.insert_many(records) ","keywords":"","version":"Next"},{"title":"ğŸ‘ Create a vector search index","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/agent-tools/create-vector-search-index","content":"ğŸ‘ Create a vector search index To retrieve documents from the knowledge base using vector search, you must configure a vector search index on the knowledge base collection. To do this, open the Database Deployments page in the Atlas UI and select Create Index in the lower right corner under Atlas Search. Click the Create Search Index button. Click JSON Editor under Atlas Vector Search to create your index Select the mongodb_agents_lab database and the knowledge collection, change the index name to vector_index, and add the following index definition in the JSON editor: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 1024, &quot;similarity&quot;: &quot;cosine&quot; } ] } info The number of dimensions in the index definition is 1024 since the Arxiv dataset we used to create the knowledge base uses Mixedbread AI's open-source mxbai-embed-large-v1 model for embeddings.","keywords":"","version":"Next"},{"title":"ğŸ¦¹ Use web search to supplement the knowledge base","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/agent-tools/add-web-search","content":"ğŸ¦¹ Use web search to supplement the knowledge base The knowledge base we created has limited information. Use web search to broaden the scope of the answer_questions_about_topics tool. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the ğŸ¦¹ Use web search to get information section in the notebook to use DuckDuckGo search if the information required to answer a particular question is not present in the knowledge base. CODE_BLOCK_17 Answer context = vector_store.similarity_search_with_score(query=query) context = [doc for doc, score in context if score &gt; 0.8] if len(context) == 0: search = DuckDuckGoSearchRun() result = search.run(query) context = [Document(page_content=result)] return context ","keywords":"","version":"Next"},{"title":"ğŸ“˜ What are AI agents?","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/ai-agents/what-are-ai-agents","content":"ğŸ“˜ What are AI agents? An AI agent is a system that uses an LLM to reason through a problem, create a plan to solve the problem, and execute the plan with the help of a set of tools. In agentic systems, one or multiple LLMs go through multiple iterations of reasoning and action-taking to reach the final answer to a user question. This means agents can handle complex, multi-step queries, and also self-revise and refine responses.","keywords":"","version":"Next"},{"title":"ğŸ“˜ Components of AI agents","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/ai-agents/components-of-agents","content":"","keywords":"","version":"Next"},{"title":"Planning and reasoningâ€‹","type":1,"pageTitle":"ğŸ“˜ Components of AI agents","url":"/ai-agents-lab/docs/ai-agents/components-of-agents#planning-and-reasoning","content":" AI agents use user prompts, self-prompting and feedback loops to break down complex tasks, reason through their execution plan and refine it as needed.  Some common design patterns for planning and reasoning in AI agents are as follows:  ","version":"Next","tagName":"h2"},{"title":"Chain of Thought (Cot) Promptingâ€‹","type":1,"pageTitle":"ğŸ“˜ Components of AI agents","url":"/ai-agents-lab/docs/ai-agents/components-of-agents#chain-of-thought-cot-prompting","content":" In this approach, the LLM is prompted to generate a step-by-step explanation or reasoning process for a given task or problem.  Here is an example of a zero-shot CoT prompt:  Given a question, write out in a step-by-step manner your reasoning for how you will solve the problem to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.  ","version":"Next","tagName":"h3"},{"title":"ReAct (Reason + Act)â€‹","type":1,"pageTitle":"ğŸ“˜ Components of AI agents","url":"/ai-agents-lab/docs/ai-agents/components-of-agents#react-reason--act","content":" In this approach, the LLM is prompted to generate reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans, while actions allow it to interface with external sources or tools, to gather additional information.  Here is an example of a ReAct prompt:  Answer the following questions as best you can. You have access to the following tools:{tools} ## Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tool_names}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now know the final answer Final Answer: the final answer to the original input question   ","version":"Next","tagName":"h3"},{"title":"Reflectionâ€‹","type":1,"pageTitle":"ğŸ“˜ Components of AI agents","url":"/ai-agents-lab/docs/ai-agents/components-of-agents#reflection","content":" Reflection involves prompting an LLM to reflect on and critique past actions, sometimes incorporating additional external information such as tool observations. The generation-reflection loop is run several times before returning the final response to the user. Reflection trades a bit of extra compute for a shot at better output quality.  ","version":"Next","tagName":"h3"},{"title":"Memoryâ€‹","type":1,"pageTitle":"ğŸ“˜ Components of AI agents","url":"/ai-agents-lab/docs/ai-agents/components-of-agents#memory","content":" The memory component allows AI agents to store and recall past conversations, enabling them to learn from these interactions.  There are two main types of memory for AI agents:  Short-term memory: Stores and retrieves information from a specific conversation. Long-term memory: Stores, retrieves and updates information based on multiple conversations had over a period of time.  ","version":"Next","tagName":"h2"},{"title":"Toolsâ€‹","type":1,"pageTitle":"ğŸ“˜ Components of AI agents","url":"/ai-agents-lab/docs/ai-agents/components-of-agents#tools","content":" Tools are interfaces for AI agents to interact with the external world and achieve their objectives. These can be APIs, vector databases, or even specialized machine learning models. ","version":"Next","tagName":"h2"},{"title":"ğŸ“˜ When to use AI agents?","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/ai-agents/when-to-use-agents","content":"ğŸ“˜ When to use AI agents? AI agents are best suited for complex, multi-step tasks that require integration of multiple capabilities, such as question-answering, analysis, task execution etc. to arrive at the final answer or outcome. An active area of research is to have AI agents learn from their past interactions to build personalized and adaptive experiences. Here are some examples of tasks/questions that DO NOT require an AI agent: Who was the first president of the United States? The information required to answer this question is very likely present in the parametric knowledge of most LLMs. Hence, this question can be answer using a simple prompt to an LLM. What is the reimbursement policy for meals for my company? The information required to answer this question is most likely not present in the parametric knowledge of available LLMs. However, this question can easily be answered using Retrieval Augmented Generation (RAG) using a knowledge base consisting of your company's data. This still does not require an agent. Here are some use cases for AI agents: How has the trend in the average daily calorie intake among adults changed over the last decade in the United States, and what impact might this have on obesity rates? Additionally, can you provide a graphical representation of the trend in obesity rates over this period? This question involves multiple sub-tasks such as data aggregation, visualization, and reasoning. Hence, this is a good use case for an AI agent. Creating a personalized learning assistant that can adjust its language, examples, and methods based on the studentâ€™s responses. This is an example of a complex task which also involves user personalization. Hence, this is a good fit for an AI agent.","keywords":"","version":"Next"},{"title":"ğŸ‘ Create agent tools","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/agent-tools/create-agent-tools","content":"ğŸ‘ Create agent tools The easiest way to define custom tools for agents in LangChain is using the @tool decorator. The decorator makes tools out of functions by using the function name as the tool name by default, and the function's docstring as the tool's description. We want the AI research agent to have access to the following tools: get_paper_metadata_arxiv: Fetches a list of research papers from Arxiv, given a topic get_paper_summary_from_arxiv: Fetches the summary for a single research paper, given a paper ID answer_questions_about_topics: Answer questions about a given topic based on information in the agent's knowledge base Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 6: Create agent tools section in the notebook to create tools for the agent to use. tip The get_paper_metadata_arxiv tool has been defined for you. Use this as inspiration to create the other two tools. The tool names and docstrings have been written out for you. All you have to do is code up the tool logic. Similarly, use the sample test for the get_paper_metadata_arxiv tool to test out the other tools. The answers for code blocks in this section are as follows: CODE_BLOCK_9 Answer doc = ArxivLoader(query=id, load_max_docs=1).get_summaries_as_docs() if len(doc) == 0: return &quot;No summary found for this paper.&quot; return doc[0].page_content CODE_BLOCK_10 Answer MongoDBAtlasVectorSearch.from_connection_string( connection_string=MONGODB_URI, namespace=DB_NAME + &quot;.&quot; + COLLECTION_NAME, embedding=embedding_model, index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME, text_key=&quot;abstract&quot;, ) CODE_BLOCK_11 Answer context = vector_store.similarity_search_with_score(query=query) context = [doc for doc, score in context if score &gt; 0.8] return context CODE_BLOCK_12 Answer retrieve = { &quot;context&quot;: RunnableLambda(get_context) | (lambda docs: &quot;\\n\\n&quot;.join([d.page_content for d in docs])), &quot;question&quot;: RunnablePassthrough(), } # Defining the chat prompt template = &quot;&quot;&quot;Answer the question based only on the following context. IF NO CONTEXT IS PROVIDED, SAY I DO NOT KNOW: \\ {context} Question: {question} &quot;&quot;&quot; prompt = ChatPromptTemplate.from_template(template) # Parse output as a string parse_output = StrOutputParser() # Retrieval chain retrieval_chain = retrieve | prompt | llm | parse_output answer = retrieval_chain.invoke(query) return answer CODE_BLOCK_13 Answer get_paper_summary_from_arxiv.invoke(&quot;1808.09236&quot;) CODE_BLOCK_14 Answer get_paper_summary_from_arxiv.invoke(&quot;808.09236&quot;) CODE_BLOCK_15 Answer answer_questions_about_topics.invoke(&quot;Partial cubes&quot;) CODE_BLOCK_16 Answer answer_questions_about_topics.invoke(&quot;Tree of Thoughts&quot;) ","keywords":"","version":"Next"},{"title":"ğŸ¦¹ Chain of Thought (CoT) prompting","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/create-agents/cot-prompting","content":"ğŸ¦¹ Chain of Thought (CoT) prompting Try out chain of thought prompting with the basic tool-calling agent. Uncomment the CoT system prompt under ğŸ¦¹ CoT prompting in the section Step 7: Create a basic tool-calling agent. Run all the cells that follow in the section to try our CoT prompting. Notice whether or not this affects the agent's behavior and response.","keywords":"","version":"Next"},{"title":"ğŸ¦¹ Create a custom agent without using abstractions","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/create-agents/agent-without-abstraction","content":"ğŸ¦¹ Create a custom agent without using abstractions The create_tool_calling_agent constructor in LangChain makes it easy to create tool-calling agents by abstracting away the individual steps involved in creating the agent. As a challenge, try creating a tool-calling agent without using the create_tool_calling_agent constructor. To do this, fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the ğŸ¦¹ Create a custom agent without using abstractions section in the notebook. The answers for code blocks in this section are as follows: CODE_BLOCK_21 Answer prompt = ChatPromptTemplate.from_messages( [ (&quot;system&quot;, system_message), (&quot;human&quot;, &quot;{input}&quot;), MessagesPlaceholder(&quot;agent_scratchpad&quot;), ] ) llm_with_tools = llm.bind_tools(tools) agent = ( RunnablePassthrough.assign( agent_scratchpad=lambda x: format_to_tool_messages(x[&quot;intermediate_steps&quot;]) ) | prompt | llm_with_tools | ToolsAgentOutputParser() ) agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, handle_parsing_errors=True ) ","keywords":"","version":"Next"},{"title":"ğŸ“˜ Tools, libraries, and concepts","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/create-agents/concepts","content":"","keywords":"","version":"Next"},{"title":"create_tool_calling_agentâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/create-agents/concepts#create_tool_calling_agent","content":" LangChain abstraction to create a basic tool-calling agent. It is essentially a sequence of Runnables that represents an agent:  ( RunnablePassthrough.assign( agent_scratchpad=lambda x: format_to_tool_messages(x[&quot;intermediate_steps&quot;]) ) | prompt | llm_with_tools | ToolsAgentOutputParser() )   ","version":"Next","tagName":"h2"},{"title":"create_react_agentâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/create-agents/concepts#create_react_agent","content":" LangChain abstraction to create a ReAct agent. It is essentially a sequence of Runnables that represents a ReAct agent:  ( RunnablePassthrough.assign( agent_scratchpad=lambda x: format_to_tool_messages(x[&quot;intermediate_steps&quot;]) ) | react_prompt | llm_with_stop | ReActSingleInputOutputParser() )   ","version":"Next","tagName":"h2"},{"title":"AgentExecutorâ€‹","type":1,"pageTitle":"ğŸ“˜ Tools, libraries, and concepts","url":"/ai-agents-lab/docs/create-agents/concepts#agentexecutor","content":" AgentExecutor is the runtime for an agent in LangChain. It is responsible for calling the agent, executing the actions it chooses, passing action outputs back to the agent, and repeating actions as needed. ","version":"Next","tagName":"h2"},{"title":"ğŸ‘ Create a ReAct agent","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/create-agents/react-agent","content":"ğŸ‘ Create a ReAct agent Now let's try out an agent that uses ReAct prompting using the create_react_agent constructor in LangChain. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 8: Create a ReAct agent section in the notebook to create a ReAct agent. The answers for code blocks in this section are as follows: CODE_BLOCK_20 Answer agent = create_react_agent(llm, tools, prompt) agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, handle_parsing_errors=&quot;Check your output. Make an observation in order to determine whether or not you have the final answer.\\ If you do, use the exact characters `Final Answer` and exit.&quot;, ) ","keywords":"","version":"Next"},{"title":"ğŸ‘ Setup prerequisites","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/dev-env/setup-pre-reqs","content":"ğŸ‘ Setup prerequisites Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 1: Install libraries and Step 2: Setup prerequisites sections in the notebook.","keywords":"","version":"Next"},{"title":"ğŸ‘ Create an API key","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/fireworks-ai/create-api-key","content":"ğŸ‘ Create an API key If you just created a new account or want to use an existing API key, skip to the last step to copy the API key. If you already have a Fireworks account and want to create a new API key, follow the steps below. Upon logging in, click the API Keys tab. Click the purple Create API Key button. In the modal that appears, enter a name and click Create Key to create an API key. Click the copy button next to your API key to copy it to your clipboard. Paste the API key somewhere safe.","keywords":"","version":"Next"},{"title":"ğŸ‘ Create an account","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/fireworks-ai/create-account","content":"ğŸ‘ Create an account In this lab, we will use FireFunction V1, a free and open-source function calling model from Fireworks AI. The easiest way to use this model is via the Fireworks API. But first, you will need to create a Fireworks account. If you already have an account, you can skip the following steps and move on to the next section. Start by navigating to the Fireworks AI homepage and click the purple Get Started Free button to create an account. Click Login With Google and authenticate with your Google account. This will provision a new Fireworks account and API Key for you.","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/intro","content":"Introduction Lab goals\tLearn the basics of building AI agentsWhat you'll learn\tWhat are AI agents When to use AI agents? Components of an AI agent Building basic tool-calling agents Different reasoning techniques for agents Adding memory to agents Time to complete\t90 mins note For this lab, you will need: Basic to intermediate knowledge of PythonA laptop with the latest version of Python installed In the navigation bar and in some pages, you will notice some icons. Here is their meaning: Icon\tMeaning\tDescriptionğŸ“˜\tLecture material\tIf you are following along in an instructor-led session, they probably have covered this already. ğŸ‘\tHands-on content\tGet ready to do some hands-on work. You should follow these steps. ğŸ“š\tDocumentation\tReference documentation for hands-on portions of the lab. ğŸ¦¹\tAdvanced content\tThis content isn't covered during the lab, but if you're interested in learning more, you can check it out.","keywords":"","version":"Next"},{"title":"ğŸ‘ Create a basic tool-calling agent","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/create-agents/tool-calling-agent","content":"ğŸ‘ Create a basic tool-calling agent Let's start by creating a basic tool-calling agent using the create_tool_calling_agent constructor in LangChain. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 7: Create a basic tool-calling agent section in the notebook to create a basic tool-calling agent. tip Skip over the ğŸ¦¸ CoT prompting section for now. Come back to it if time permits. The answers for code blocks in this section are as follows: CODE_BLOCK_18 Answer f&quot;&quot;&quot;Answer the following questions as best you can. You can answer directly if the user is greeting you or similar. Otherwise, you have access to the following tools: {render_text_description(tools)} &quot;&quot;&quot; CODE_BLOCK_19 Answer prompt = ChatPromptTemplate.from_messages( [ (&quot;system&quot;, system_message), (&quot;human&quot;, &quot;{input}&quot;), MessagesPlaceholder(&quot;agent_scratchpad&quot;), ] ) agent = create_tool_calling_agent(llm, tools, prompt) agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, handle_parsing_errors=True ) ","keywords":"","version":"Next"},{"title":"ğŸ‘ Setup dev environment","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/dev-env/dev-setup","content":"","keywords":"","version":"Next"},{"title":"Local setupâ€‹","type":1,"pageTitle":"ğŸ‘ Setup dev environment","url":"/ai-agents-lab/docs/dev-env/dev-setup#local-setup","content":" If you want to run the notebook locally, follow the steps below:  Clone the GitHub repo for this lab by executing the following command from the terminal:  git clone https://github.com/mongodb-developer/ai-agents-lab-notebooks.git   cd into the cloned directory:  cd ai-agents-lab-notebooks   Create and activate a Python virtual environment:  python -m venv mongodb-ai-agents-lab source mongodb-ai-agents-lab/bin/activate   Install and launch Jupyter Notebook:  pip install notebook jupyter notebook   In the browser tab that pops up, open the notebook named notebook_template.ipynb.   ","version":"Next","tagName":"h2"},{"title":"ğŸ‘ Create an API key","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/langsmith/create-api-key","content":"ğŸ‘ Create an API key To see traces in LangSmith, you need an API key. Once logged into your account, click the gear icon on the sidebar. This should take you to the API Keys page. Click the blue Create API Key button to create a new API key. In the modal that appears, assign a name for the key, and copy it to a safe place when prompted.","keywords":"","version":"Next"},{"title":"ğŸ‘ Create an account","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/langsmith/create-account","content":"ğŸ‘ Create an account In this lab, we will use LangChain to build an AI research agent. LangSmith is a platform that can help visualize the series of steps taken by an LLM application built using LangChain, to go from input to output. You can use LangSmith during the lab for debugging. To use LangSmith, you will first need to create an account. Start by navigating to LangSmith Sign Up page and choose between the options provided to create your account. info If you already have an account, click Already have an account? Log In instead to log into your account.","keywords":"","version":"Next"},{"title":"ğŸ‘ Get your connection string","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/mongodb-atlas/get-connection-string","content":"ğŸ‘ Get your connection string In order to ingest data into your cluster later in the lab, you will need to get the connection string for your cluster. In the Atlas UI, navigate to the Overview page. In the Clusters section, select the cluster you just created and click Connect. A modal will display several ways to connect to your database. Select Compass. While we won't be using Compass to import the data, it's an easy way to see your connection string. Look for your connection string. It should look something like: mongodb+srv://&lt;username&gt;:&lt;password&gt;@&lt;cluster-url&gt;/ Click the copy button next to your connection string to copy it to your clipboard. Paste the connection string somewhere safe. tip Don't forget to replace &lt;password&gt; with the password you set when you created the cluster.","keywords":"","version":"Next"},{"title":"ğŸ‘ Deploy a database cluster","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/mongodb-atlas/create-cluster","content":"","keywords":"","version":"Next"},{"title":"Security quickstartâ€‹","type":1,"pageTitle":"ğŸ‘ Deploy a database cluster","url":"/ai-agents-lab/docs/mongodb-atlas/create-cluster#security-quickstart","content":" By default, your MongoDB Atlas deployment is completely locked-down. You need to configure the network settings and create a user to access your database.  While your deployment is being provisioned, you will see the security quickstart dialog.  ","version":"Next","tagName":"h2"},{"title":"Network accessâ€‹","type":1,"pageTitle":"ğŸ‘ Deploy a database cluster","url":"/ai-agents-lab/docs/mongodb-atlas/create-cluster#network-access","content":" First, you should Allow Access from Anywhere. You will see a field pre-populated with the IP address 0.0.0.0/0. This means that you can connect to your database from any IP address including the virtual environment you will use for this lab. Click Add IP Address to add this IP address to the network allowlist.  caution It is dangerous to expose your database to the entire world. Never do this is a real production environment.  ","version":"Next","tagName":"h3"},{"title":"Database userâ€‹","type":1,"pageTitle":"ğŸ‘ Deploy a database cluster","url":"/ai-agents-lab/docs/mongodb-atlas/create-cluster#database-user","content":" Next, you need to create a database user. Pick any username and password you want. This will be used when you want to connect to your database. Click Create Database User to create the user.  Atlas might create the user automatically for you if you have just created your account. In this case, the username and password will match your Atlas account credentials.  tip Make sure to remember your username and password. You will need them later. For the sake of this workshop, it might be preferable to use a simple password that you'll remember over a more secure one.  ","version":"Next","tagName":"h3"},{"title":"Manual network access configurationâ€‹","type":1,"pageTitle":"ğŸ‘ Deploy a database cluster","url":"/ai-agents-lab/docs/mongodb-atlas/create-cluster#manual-network-access-configuration","content":" If you don't see a button to Allow Access from Anywhere, you should close the dialog and go to the Network Access tab under the Security section in the left sidebar. Click on the Add IP Address button, add the IP address 0.0.0.0/0 and click Confirm.  ","version":"Next","tagName":"h2"},{"title":"That's all!â€‹","type":1,"pageTitle":"ğŸ‘ Deploy a database cluster","url":"/ai-agents-lab/docs/mongodb-atlas/create-cluster#thats-all","content":" That's all! You have a new database cluster. If everything goes well, you should see your newly created cluster on the Database tab under the Deployment section.   ","version":"Next","tagName":"h2"},{"title":"ğŸ‘ Create your account","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/mongodb-atlas/create-account","content":"","keywords":"","version":"Next"},{"title":"Sign up for MongoDB Atlasâ€‹","type":1,"pageTitle":"ğŸ‘ Create your account","url":"/ai-agents-lab/docs/mongodb-atlas/create-account#sign-up-for-mongodb-atlas","content":" Start by going to the MongoDB website and creating your account.  tip Creating a MongoDB Atlas account is free and does not require a credit card.  You will be greeted by a form similar to the one below.    info If you are doing this lab at an event, you should use the same email address you used to register for the event.  Complete the form and click the Create Your Atlas Account button.  ","version":"Next","tagName":"h2"},{"title":"Verify your email addressâ€‹","type":1,"pageTitle":"ğŸ‘ Create your account","url":"/ai-agents-lab/docs/mongodb-atlas/create-account#verify-your-email-address","content":" You will receive an email from MongoDB asking you to verify your email address. Click the link in the email to verify your email address.    caution If you haven't received the email within two minutes, check your spam folder.  ","version":"Next","tagName":"h2"},{"title":"Finish the onboardingâ€‹","type":1,"pageTitle":"ğŸ‘ Create your account","url":"/ai-agents-lab/docs/mongodb-atlas/create-account#finish-the-onboarding","content":" You will be redirected to the MongoDB Atlas onboarding wizard. Fill in the form and click Finish to continue. ","version":"Next","tagName":"h2"},{"title":"ğŸ¯ Summary","type":0,"sectionRef":"#","url":"/ai-agents-lab/docs/summary","content":"ğŸ¯ Summary Congratulations! Following this lab, you have successfully: learned what are AI agentslearned when to use AI agentsbuilt a basic tool-calling agentbuilt a ReAct agentbuilt an agent with memory Here are some resources that you might find helpful: MongoDB Developer CenterGenAI Code Examples RepositoryGenAI Community Forums","keywords":"","version":"Next"}],"options":{"id":"default"}}