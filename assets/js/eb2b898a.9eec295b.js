"use strict";(self.webpackChunkai_agents_lab=self.webpackChunkai_agents_lab||[]).push([[390],{521:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>h});var a=t(4848),s=t(8453);const i={},o="\ud83d\udcd8 Concepts",r={id:"create-agent/concepts",title:"\ud83d\udcd8 Concepts",description:"Here is a quick overview of concepts that you will come across in this section of the lab:",source:"@site/docs/50-create-agent/1-concepts.mdx",sourceDirName:"50-create-agent",slug:"/create-agent/concepts",permalink:"/ai-agents-lab/docs/create-agent/concepts",draft:!1,unlisted:!1,editUrl:"https://github.com/mongodb-developer/ai-agents-lab/blob/main/docs/50-create-agent/1-concepts.mdx",tags:[],version:"current",sidebarPosition:1,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Create Agent",permalink:"/ai-agents-lab/docs/category/create-agent"},next:{title:"\ud83d\udc50 Define graph state",permalink:"/ai-agents-lab/docs/create-agent/define-graph-state"}},c={},h=[{value:"Creating agents using LangGraph",id:"creating-agents-using-langgraph",level:2},{value:"State",id:"state",level:3},{value:"Nodes",id:"nodes",level:3},{value:"Edges",id:"edges",level:3},{value:"Using different LLM providers with LangChain",id:"using-different-llm-providers-with-langchain",level:2}];function l(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"-concepts",children:"\ud83d\udcd8 Concepts"})}),"\n",(0,a.jsx)(n.p,{children:"Here is a quick overview of concepts that you will come across in this section of the lab:"}),"\n",(0,a.jsx)(n.h2,{id:"creating-agents-using-langgraph",children:"Creating agents using LangGraph"}),"\n",(0,a.jsx)(n.p,{children:"In this lab, we will use LangGraph by LangChain to orchestrate a technical documentation agent. LangGraph allows you to model agentic systems as graphs. Graphs in LangGraph have the following core features:"}),"\n",(0,a.jsx)(n.h3,{id:"state",children:"State"}),"\n",(0,a.jsx)(n.p,{children:"Each graph in has a state which is a shared data structure that all the nodes can access and make updates to. You can define custom attributes within the state depending on what parameters you want to track across the nodes of the graph."}),"\n",(0,a.jsx)(n.h3,{id:"nodes",children:"Nodes"}),"\n",(0,a.jsx)(n.p,{children:"Nodes in LangGraph are Python functions that encode the logic of your agents. They receive the current state of the graph as input, perform some computation and return an updated state."}),"\n",(0,a.jsx)(n.h3,{id:"edges",children:"Edges"}),"\n",(0,a.jsx)(n.p,{children:"Edges in LangGraph are Python functions that determine which graph node to execute next based on the current state of the graph. Edges can be conditional or fixed."}),"\n",(0,a.jsx)(n.h2,{id:"using-different-llm-providers-with-langchain",children:"Using different LLM providers with LangChain"}),"\n",(0,a.jsx)(n.p,{children:"LangChain supports different LLM providers for you to build AI applications with. Unless you are using open-source models, you typically need to obtain API keys to use the chat completion APIs offered by different LLM providers."}),"\n",(0,a.jsx)(n.p,{children:"For this lab, we have created a serverless function that creates LLM objects for Amazon, Google and Microsoft models that you can use with LangChain and LangGraph without having to obtain API keys. However, if you would like to do this on your own, here are some resources:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://python.langchain.com/docs/integrations/llms/bedrock/",children:"Using Amazon Bedrock LLMs with LangChain"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://python.langchain.com/docs/integrations/chat/google_generative_ai/",children:"Using Google LLMs with LangChain"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://python.langchain.com/docs/integrations/chat/azure_chat_openai/",children:"Using Microsoft LLMs with langChain"})}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var a=t(6540);const s={},i=a.createContext(s);function o(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);